Running over 200 epochs unless othewise indicated


Base setup.  First run.   SGD optimizer

Git version  (git rev-parse HEAD):    d098b5b74d9ac7bb3beb40b1be2535332f914892

RPRED:  Rain starting in 1-2 hours, warning rate= 0 / 137: 0.0
RPRED:  Rain starting in 3-6 hours, warning rate= 0.0
RPRED:  Rain stopping in next hour, warning rate= 0.0
RPRED:  Rain stopping in 3-6 hours, warning rate= 0.0
Total confusion= [[[402   0]
  [240   5]]

 [[558   0]
  [ 89   0]]

 [[368   0]
  [279   0]]

 [[548   0]
  [ 99   0]]

 [[401   0]
  [246   0]]

 [[558   0]
  [ 89   0]]

 [[379   0]
  [268   0]]

 [[556   0]
  [ 91   0]]

 [[395   0]
  [252   0]]

 [[570   0]
  [ 77   0]]]





Experiment #1:  RMSProp optimizer

Git version

RPRED:  Rain starting in 1-2 hours, warning rate= 112 / 137: 0.8175182481751825
RPRED:  Rain starting in 3-6 hours, warning rate= 0.842741935483871
RPRED:  Rain stopping in next hour, warning rate= 0.6470588235294118
RPRED:  Rain stopping in 3-6 hours, warning rate= 0.0
Total confusion= [[[376  26]
  [ 38 207]]

 [[546  12]
  [ 17  72]]

 [[355  13]
  [ 53 226]]

 [[542   6]
  [ 30  69]]

 [[382  19]
  [ 32 214]]

 [[550   8]
  [ 19  70]]

 [[359  20]
  [ 33 235]]

 [[549   7]
  [ 14  77]]

 [[368  27]
  [ 44 208]]

 [[561   9]
  [ 15  62]]]




Experiment #2:  Adagrad optimizer

Git version

RPRED:  Rain starting in 1-2 hours, warning rate= 108 / 137: 0.7883211678832117
RPRED:  Rain starting in 3-6 hours, warning rate= 0.842741935483871
RPRED:  Rain stopping in next hour, warning rate= 0.7647058823529411
RPRED:  Rain stopping in 3-6 hours, warning rate= 0.0
Total confusion= [[[375  27]
  [ 26 219]]

 [[548  10]
  [ 17  72]]

 [[353  15]
  [ 56 223]]

 [[539   9]
  [ 16  83]]

 [[378  23]
  [ 28 218]]

 [[546  12]
  [ 12  77]]

 [[362  17]
  [ 51 217]]

 [[550   6]
  [ 19  72]]

 [[364  31]
  [ 35 217]]

 [[554  16]
  [ 13  64]]]




Expriment #3.  Adadelta optimizer

Git version: 

RPRED:  Rain starting in 1-2 hours, warning rate= 105 / 137: 0.7664233576642335
RPRED:  Rain starting in 3-6 hours, warning rate= 0.7620967741935484
RPRED:  Rain stopping in next hour, warning rate= 0.7647058823529411
RPRED:  Rain stopping in 3-6 hours, warning rate= 0.0
Total confusion= [[[357  45]
  [ 23 222]]

 [[544  14]
  [ 15  74]]

 [[352  16]
  [ 64 215]]

 [[538  10]
  [ 22  77]]

 [[368  33]
  [ 41 205]]

 [[549   9]
  [ 23  66]]

 [[355  24]
  [ 64 204]]

 [[550   6]
  [ 29  62]]

 [[355  40]
  [ 41 211]]

 [[558  12]
  [ 15  62]]]




Experiment #4:  Adam optimizer

Git version 

RPRED:  Rain starting in 1-2 hours, warning rate= 105 / 137: 0.7664233576642335
RPRED:  Rain starting in 3-6 hours, warning rate= 0.8508064516129032
RPRED:  Rain stopping in next hour, warning rate= 0.8235294117647058
RPRED:  Rain stopping in 3-6 hours, warning rate= 0.0
Total confusion= [[[367  35]
  [ 35 210]]

 [[541  17]
  [ 15  74]]

 [[351  17]
  [ 51 228]]

 [[539   9]
  [ 17  82]]

 [[365  36]
  [ 27 219]]

 [[548  10]
  [ 12  77]]

 [[345  34]
  [ 31 237]]

 [[550   6]
  [ 19  72]]

 [[361  34]
  [ 34 218]]

 [[556  14]
  [ 11  66]]]



Experiment #5.  Adamax optimizer

Git version  


RPRED:  Rain starting in 1-2 hours, warning rate= 111 / 137: 0.8102189781021898
RPRED:  Rain starting in 3-6 hours, warning rate= 0.7459677419354839
RPRED:  Rain stopping in next hour, warning rate= 0.7647058823529411
RPRED:  Rain stopping in 3-6 hours, warning rate= 0.0
Total confusion= [[[359  43]
  [ 23 222]]

 [[542  16]
  [ 13  76]]

 [[348  20]
  [ 40 239]]

 [[539   9]
  [ 20  79]]

 [[353  48]
  [ 32 214]]

 [[546  12]
  [ 14  75]]

 [[351  28]
  [ 64 204]]

 [[550   6]
  [ 27  64]]

 [[372  23]
  [ 56 196]]

 [[557  13]
  [ 19  58]]]



Experiment #6.  Nadam optimizer

Git version 


RPRED:  Rain starting in 1-2 hours, warning rate= 110 / 137: 0.8029197080291971
RPRED:  Rain starting in 3-6 hours, warning rate= 0.7379032258064516
RPRED:  Rain stopping in next hour, warning rate= 0.7058823529411765
RPRED:  Rain stopping in 3-6 hours, warning rate= 0.0
Total confusion= [[[365  37]
  [ 42 203]]

 [[541  17]
  [ 14  75]]

 [[348  20]
  [ 61 218]]

 [[541   7]
  [ 24  75]]

 [[375  26]
  [ 30 216]]

 [[544  14]
  [ 14  75]]

 [[349  30]
  [ 45 223]]

 [[551   5]
  [ 18  73]]

 [[370  25]
  [ 67 185]]

 [[560  10]
  [ 15  62]]]



===============================================================


Tweaking Expt #1

Tweaking the network.  predictor.py creates a custom error measure, a
weighted sum of departures for those entries that failed.  Using 40
histogramming bins.

First version.  39a6ab2d40f8c1ef21c1ca5e8f0d3dd44102bd93
All layers relu.  Node counts 500,300,10
No regularization

Custom Error Measure= 6965.599999999999


Tweaking Expt #2

LSTM layer sigmoid.  All other layers relu.  Node counts 500,300,10
No regularization

Version 078cd9930ae2372ce3fd05b53457aff58a8719b6

Custom Error Measure= 7434.300000000001


Tweaking Expt #3

LSTM layer tanh.  All other layers relu.  Node counts 500,300,10
No regularization

Version 597bbb39f47510c91b3decf6c8634707167452e2

Custom Error Measure= 7187.699999999996


Tweaking Expt #4

Leaving LSTM layer at tanh.  Turning the synthesis layer to LeakyReLU.
Otherwise as above.

Version 4b1db3cfefbe40c6e28b69bd33a3a6bb9c2e631d

Custom Error Measure= 7168.699999999999


Tweaking Expt #5

Synthesis layer back to ReLU.  Add another layer between it and the
output layer.

Version 2bfef4bcd6f55416e5287bbaeda4a3aff1aa7ede

Custom Error Measure= 7753.499999999999



///////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////

Starting over with cleanly disjoint data, and much more data.

500/300/10 network is badly overtrained from epoch 2

100/300/10 network is as above

80/40/10  as above

Went down as far as 10/10/10, still overfitting

Added a dense layer below the LSTM layer, new geometry:
40/10/10/10

Added normalization and dropout layers:
40/N/D/10/D/10/N/10
still overfitting





///////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////


New pre-processing.  Rain pixel fraction, mean rain, RMS rain

Monitoring binary accuracy.  Reporing mean and stddev over 4 trials.


geometry_layer_nodes = 30
lstm_module_nodes = 10
synth_layer_nodes = 10
num_outputs = 10

            inputs1 = Input
            inputsM = Input

            geometry_layer = Dense(activation='relu')
            drop_layer1 = Dropout(rate=0.25)
            time_layer1 = LSTM(lstm_module_nodes, stateful = False,
                               return_sequences = True,
                               activation='relu')
            time_layer2 = LSTM(lstm_module_nodes, stateful = False,
                               return_sequences = False,
                               activation='relu')
            drop_layer2 = Dropout(rate=0.25)
            concat = Concatenate()([drop_layer2, inputsM])
            synth_layer1 = Dense(synth_layer_nodes, activation='relu')
            synth_layer2 = Dense(synth_layer_nodes, activation='relu')
            output_layer = Dense(num_outputs, activation='sigmoid')


for optimizer in [ keras.optimizers.Adagrad(), keras.optimizers.Adadelta(),
                   keras.optimizers.Adam(), keras.optimizers.Adamax(),
                   keras.optimizers.Nadam(),
                   keras.optimizers.RMSprop()]:
    for batch_size in [ 128, 256, 512, 1024 ]:



<keras.optimizers.Adagrad object at 0x7ff5de84ac10> 128 : 0.8860821092987271 0.0002839883863820208
<keras.optimizers.Adagrad object at 0x7ff5de84ac10> 256 : 0.8870710977191589 0.000880163670708477
<keras.optimizers.Adagrad object at 0x7ff5de84ac10> 512 : 0.8862319422406267 0.0015270220285323577
<keras.optimizers.Adagrad object at 0x7ff5de84ac10> 1024 : 0.8859614225754376 0.0005515986780684213
<keras.optimizers.Adadelta object at 0x7ff5de84a050> 128 : 0.8855070632190758 0.0013077720933831302
<keras.optimizers.Adadelta object at 0x7ff5de84a050> 256 : 0.8861432941717791 0.0004077690584907566
<keras.optimizers.Adadelta object at 0x7ff5de84a050> 512 : 0.8864099314760169 0.0010167975609776173
<keras.optimizers.Adadelta object at 0x7ff5de84a050> 1024 : 0.8861112162014292 0.0014898036863940911
<keras.optimizers.Adam object at 0x7ff5de84a250> 128 : 0.8856472002637512 0.002290273373295813
<keras.optimizers.Adam object at 0x7ff5de84a250> 256 : 0.8858670476347718 0.00011999298074812856
<keras.optimizers.Adam object at 0x7ff5de84a250> 512 : 0.8857036066093318 0.0014050616372488917
<keras.optimizers.Adam object at 0x7ff5de84a250> 1024 : 0.8854226170319004 0.001524995209186944
<keras.optimizers.Adamax object at 0x7ff5de896b90> 128 : 0.8888316970330677 0.0007182968596919951
<keras.optimizers.Adamax object at 0x7ff5de896b90> 256 : 0.8871669401978599 0.0014917134730436808
<keras.optimizers.Adamax object at 0x7ff5de896b90> 512 : 0.887957082612913 0.0018812014213776317
<keras.optimizers.Adamax object at 0x7ff5de896b90> 1024 : 0.8862771327047748 0.0010431172730844718
<keras.optimizers.Nadam object at 0x7ff5de8a5dd0> 128 : 0.8851148376316874 0.0009227898326317715
<keras.optimizers.Nadam object at 0x7ff5de8a5dd0> 256 : 0.8860474532964376 0.001510945503096132
<keras.optimizers.Nadam object at 0x7ff5de8a5dd0> 512 : 0.8847371396866046 0.0010451914886944493
<keras.optimizers.Nadam object at 0x7ff5de8a5dd0> 1024 : 0.8852317348376542 0.0013487252753214816
<keras.optimizers.RMSprop object at 0x7ff434edcb50> 128 : 0.8877581151564218 0.00043066100024175187
<keras.optimizers.RMSprop object at 0x7ff434edcb50> 256 : 0.8888075068582943 0.0021124450959025035
<keras.optimizers.RMSprop object at 0x7ff434edcb50> 512 : 0.887671976613824 0.000977297292981032
<keras.optimizers.RMSprop object at 0x7ff434edcb50> 1024 : 0.8874876370023987 0.0006220745223378001





            inputs1 = Input
            inputsM = Input

            geometry_layer = Dense(activation='relu')
            drop_layer1 = Dropout(rate=0.25)
            time_layer2 = LSTM(lstm_module_nodes, stateful = False,
                               return_sequences = False,
                               activation='relu')
            drop_layer2 = Dropout(rate=0.25)
            concat = Concatenate()([drop_layer2, inputsM])
            synth_layer1 = Dense(synth_layer_nodes, activation='relu')
            output_layer = Dense(num_outputs, activation='sigmoid')

<keras.optimizers.Adagrad object at 0x7f09411d7bd0> 128 : 0.8887986753849151 0.0016355941243708315
<keras.optimizers.Adagrad object at 0x7f09411d7bd0> 256 : 0.8895782607686662 0.0014168213002399618
<keras.optimizers.Adagrad object at 0x7f09411d7bd0> 512 : 0.8881294325463094 0.000392375834205088
<keras.optimizers.Adagrad object at 0x7f09411d7bd0> 1024 : 0.8878758335324939 0.0015859869793762753
<keras.optimizers.Adadelta object at 0x7f094121ed90> 128 : 0.8884032317170055 0.0017460609230529943
<keras.optimizers.Adadelta object at 0x7f094121ed90> 256 : 0.8896966548747867 0.001117503338894346
<keras.optimizers.Adadelta object at 0x7f094121ed90> 512 : 0.8892360383110107 0.0007600977373459602
<keras.optimizers.Adadelta object at 0x7f094121ed90> 1024 : 0.8872065517466567 0.001548859073782688
<keras.optimizers.Adam object at 0x7f094122cb50> 128 : 0.8884499427836632 0.0013094173433076204
<keras.optimizers.Adam object at 0x7f094122cb50> 256 : 0.8891344934467657 0.0011633492762776578
<keras.optimizers.Adam object at 0x7f094122cb50> 512 : 0.8887511914524735 0.000529774877024729
<keras.optimizers.Adam object at 0x7f094122cb50> 1024 : 0.8886715607876469 0.0006859508054446664
<keras.optimizers.Adamax object at 0x7f094122cb90> 128 : 0.8889839143758198 0.0010510017174118814
<keras.optimizers.Adamax object at 0x7f094122cb90> 256 : 0.8897320901294148 0.000730944681541122
<keras.optimizers.Adamax object at 0x7f094122cb90> 512 : 0.8886239420616466 0.0018762111149504472
<keras.optimizers.Adamax object at 0x7f094122cb90> 1024 : 0.8882897968931238 0.0016773529443049877
<keras.optimizers.Nadam object at 0x7f094122cd90> 128 : 0.8876026783419702 0.002451361904670787
<keras.optimizers.Nadam object at 0x7f094122cd90> 256 : 0.8874222411910944 0.0014872141456719098
<keras.optimizers.Nadam object at 0x7f094122cd90> 512 : 0.8865798689891358 0.0008913166961054979
<keras.optimizers.Nadam object at 0x7f094122cd90> 1024 : 0.8871920609542541 0.0019172427110081434
<keras.optimizers.RMSprop object at 0x7f094122c890> 128 : 0.8903313252816498 0.0006076774540648202
<keras.optimizers.RMSprop object at 0x7f094122c890> 256 : 0.8888985163735528 0.0008941862608967118
<keras.optimizers.RMSprop object at 0x7f094122c890> 512 : 0.8899584715043234 0.0008864485310891043
<keras.optimizers.RMSprop object at 0x7f094122c890> 1024 : 0.8897926505775182 0.0009601440370948196


for geometry_layer_nodes in [ 10, 20, 30, 40, 50]:
    for lstm_module_nodes in [ 5, 10, 15, 20, 25, 30]:

GLN: 10 LMN: 5 : 0.8848893605317848 0.0017218064456928678
GLN: 10 LMN: 10 : 0.8888132078915442 0.0005107894806635509
GLN: 10 LMN: 15 : 0.8894889309782945 0.0020092929028619477
GLN: 10 LMN: 20 : 0.8892771081468431 0.0010926394538358266
GLN: 10 LMN: 25 : 0.8891981818315497 0.0028537758886603664
GLN: 10 LMN: 30 : 0.8907719090374999 0.000643236615206668
GLN: 20 LMN: 5 : 0.8845358014184518 0.0009750292391046624
GLN: 20 LMN: 10 : 0.8897474598359028 0.0008479512034508914
GLN: 20 LMN: 15 : 0.8899939060307192 0.000984421810384982
GLN: 20 LMN: 20 : 0.8903249204129979 0.0006647541113927823
GLN: 20 LMN: 25 : 0.8913646751862281 0.00030488205901276643
GLN: 20 LMN: 30 : 0.8913058763605921 0.00033356302752898304
GLN: 30 LMN: 5 : 0.8875970738395957 0.001183596031927565
GLN: 30 LMN: 10 : 0.8899979316830339 0.0005052213607407071
GLN: 30 LMN: 15 : 0.8902596824332221 0.0009467325141602227
GLN: 30 LMN: 20 : 0.8910803727668561 0.000498070912790744
GLN: 30 LMN: 25 : 0.8910932573104756 0.0002745996197593428
GLN: 30 LMN: 30 : 0.8917021300739812 0.0008479908808774641
GLN: 40 LMN: 5 : 0.8872926359857765 0.0012967874961285334
GLN: 40 LMN: 10 : 0.8906333820047017 0.0002410431327007596
GLN: 40 LMN: 15 : 0.8909998330606297 0.00043815497494782306
GLN: 40 LMN: 20 : 0.8911584930844323 0.0005077537242554728
GLN: 40 LMN: 25 : 0.8914854833755115 0.0008068258549420187
GLN: 40 LMN: 30 : 0.8913630614458203 0.0006584953524703881
GLN: 50 LMN: 5 : 0.8883315862979222 0.0013011720173112978
GLN: 50 LMN: 10 : 0.8891740231887109 0.001340334633380931
GLN: 50 LMN: 15 : 0.8907743229051214 0.0007846710269487009
GLN: 50 LMN: 20 : 0.8921708651941918 0.00030727547199595916
GLN: 50 LMN: 25 : 0.8918640116447294 0.000531999986239723
GLN: 50 LMN: 30 : 0.8922071050323164 0.0006965406381843089
